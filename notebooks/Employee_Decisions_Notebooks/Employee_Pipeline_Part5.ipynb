{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SXeP21YL6nu"
      },
      "source": [
        "# Employee Pipeline Part 5:\n",
        "\n",
        "After having concluded a better prompt overall, this is our attempt at augmenting the query itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "midjOkJXL45E",
        "outputId": "84b6d924-9578-4e0a-ab17-46aa4c932306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.9)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain_community)\n",
            "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.11 langchain-core-0.3.24 langchain_community-0.3.11 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.26.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.24)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.2.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.20.3)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.1.2\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting aiohttp<3.10,>=3.9.5 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.3.24)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (4.66.6)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (2.27.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.2.2)\n",
            "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client, aiohttp, langchain_pinecone\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.9\n",
            "    Uninstalling aiohttp-3.11.9:\n",
            "      Successfully uninstalled aiohttp-3.11.9\n",
            "Successfully installed aiohttp-3.9.5 langchain_pinecone-0.2.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, pinecone\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 1.1.0\n",
            "    Uninstalling pinecone-plugin-inference-1.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone-client 5.0.1 requires pinecone-plugin-inference<2.0.0,>=1.0.3, but you have pinecone-plugin-inference 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "Installing collected packages: pinecone-plugin-inference\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 3.1.0\n",
            "    Uninstalling pinecone-plugin-inference-3.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-plugin-inference-1.1.0\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.41.0-py2.py3-none-any.whl (23.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.0 watchdog-6.0.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement difflib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for difflib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting cohere\n",
            "  Downloading cohere-5.13.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, fastavro, cohere\n",
            "Successfully installed cohere-5.13.3 fastavro-1.9.7 parameterized-0.9.0 types-requests-2.32.0.20241016\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.13.3)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "#pip installing:\n",
        "%pip install langchain\n",
        "%pip install langchain_community\n",
        "%pip install langchain_huggingface\n",
        "%pip install langchain_pinecone\n",
        "%pip install pinecone\n",
        "%pip install pinecone-client\n",
        "%pip install dotenv\n",
        "%pip install streamlit\n",
        "%pip install pymupdf\n",
        "%pip install -qU langchain_community wikipedia\n",
        "%pip install --upgrade --quiet langchain-text-splitters tiktoken\n",
        "%pip install difflib\n",
        "%pip install cohere\n",
        "%pip install cohere\n",
        "\n",
        "\n",
        "import os\n",
        "import langchain #its giving module not found error\n",
        "import langchain_community\n",
        "import langchain_huggingface\n",
        "import langchain_pinecone\n",
        "import pinecone\n",
        "import dotenv\n",
        "import streamlit as st\n",
        "\n",
        "# Additional Imports (loading document):\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "#pinecone etc (storage of ducments):\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from uuid import uuid4\n",
        "\n",
        "#hugging face etc (for generation):\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "#memory imports\n",
        "#I used these documentations: https://python.langchain.com/v0.1/docs/use_cases/chatbots/memory_management/ , https://python.langchain.com/v0.1/docs/modules/memory/types/buffer/ , https://python.langchain.com/v0.1/docs/modules/memory/\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import create_history_aware_retriever #new\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#caching imports:\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "#for timing the retrivals\n",
        "import time\n",
        "\n",
        "#for parsing:\n",
        "import re\n",
        "\n",
        "#for cohere:\n",
        "import cohere\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gInmxNrMHF0",
        "outputId": "64a9183d-84be-4b0b-b17f-fe098087024d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables are saved to .env file.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace with the API keys you need\n",
        "HUGGINGFACE_API_KEY = \"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\"\n",
        "PINECONE_API_KEY = \"pcsk_53kMBB_46NnPeyFBe4q6LFpksKpKVkTr2q2L3w6uwDk3YnfmwMxWMNYrRCQniNzBoepwDi\"\n",
        "COHERE_API_KEY = \"\"\n",
        "\n",
        "env_content = f\"\"\"\n",
        "HUGGINGFACE_API_KEY={HUGGINGFACE_API_KEY}\n",
        "PINECONE_API_KEY={PINECONE_API_KEY}\n",
        "COHERE_API_KEY={COHERE_API_KEY}\n",
        "\"\"\"\n",
        "\n",
        "with open(\".env\", \"w\") as file:\n",
        "    file.write(env_content)\n",
        "\n",
        "print(\"Environment variables are saved to .env file.\")\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vedpFnodMKJl"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.retriever = self.vector_store.as_retriever( search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.5},) #tunable\n",
        "        self.repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 0.8, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "\n",
        "        #memory variables:\n",
        "        self.memory_template = \"\"\"You are a ambiguity clearer, your task is to examine the human question and check for any \"he/she/it/they/them\" ambiguities.\n",
        "        return an updated human question fixing those ambiguities using the previous conversation context only.\n",
        "        if there is not enought relevant context, RETURN HUMAN QUESTION AS IT IS\n",
        "        YOUR ANSWER SHOULD BE A QUESTION WHICH ONLY CLARIFIES ANY AMBIGUITY IN human question by replacing it with their name\n",
        "        RETURN IN FORMAT: New human question: (updated question)\n",
        "        Previous conversation:\n",
        "        {chat_history}\n",
        "\n",
        "        human question: {question}\n",
        "        New human question:\n",
        "        \"\"\"\n",
        "        self.memory_prompt = PromptTemplate.from_template(self.memory_template)\n",
        "\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "        self.conversation = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.memory_prompt,\n",
        "            verbose=False,\n",
        "            memory=self.memory\n",
        "        )\n",
        "        #prompt variables\n",
        "        self.Classifier_template = \"\"\"\n",
        "        You are a prompt classifier designed to classify questions from employees in an organization.\n",
        "        classify the following question into \"Relevant\" or \"Irrelevant\", based on whether the query theme is of a question from an organization employee, the question could be about IT, HR, Finance or any other department\n",
        "        Only answer from the specified classes and one word answers.\n",
        "\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #Case 4: (chain of thought with few shot examples)\n",
        "        self.Employee_Template = \"\"\"\n",
        "            You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "            Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "            Follow these steps to construct your response:\n",
        "            1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "            2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "            3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "            4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "            5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "            Examples:\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "            Question:\n",
        "            \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "            2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "            3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "            4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "            5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "            Question:\n",
        "            \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "            2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "            3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "            4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "            5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "            ---\n",
        "            Context: {context}\n",
        "            Question: {question}\n",
        "            Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        self.Classifier_prompt = PromptTemplate( template=self.Classifier_template, input_variables=[\"question\"] )\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.classifier_chain = ({\"question\": RunnablePassthrough()} | self.Classifier_prompt | self.llm  | StrOutputParser() )\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"context\": self.retriever | self.format_docs,  \"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "        self.full_chain = {\"Relevancy\": self.classifier_chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(self.route)\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "        # print(f\"Generating with system prompt: {self.Employee_Template}\")\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        query = query + \" try to answer from \" + relevant_docs\n",
        "        print(f\"Augmented Query is: {query}\")\n",
        "        query_response = self.full_chain.invoke({\"question\": query})\n",
        "        # Apply regex to extract \"Provide the answer\" part's content\n",
        "        match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "        # Return the extracted content or an empty string if no match is found\n",
        "        if self.verbose:\n",
        "          return query_response\n",
        "        else:\n",
        "          return match.group(1) if match else \"\"\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "    def route(self, info):\n",
        "        if \"relevant\" in info[\"Relevancy\"].lower():\n",
        "          # print(\"Question was relevant\")\n",
        "          return self.Employee_chain.invoke(info[\"question\"])\n",
        "        else:\n",
        "          return \"Your question was not relevant to our organization\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_4xj_muMSL_"
      },
      "outputs": [],
      "source": [
        "bot = EmployeeChatBot()\n",
        "# bot.augment_query(\"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-1W9JtIWhEx"
      },
      "source": [
        "# Reflection:\n",
        "\n",
        "So in this case, i saw as i gave a few shot examples, the LLM response became too hallucinated and it started giving reasonings and further examples in the response. then i toned down the augment prompt and applied Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "TvZpfERsYA8t",
        "outputId": "faa3fbe8-ed6b-418b-f1dd-20d2d1ff86fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented Query is: At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week? try to answer from Employee-Handbook, Onboarding-Manual\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Eligible employees can be compensated for the following holidays: New Years Day, Labor Day, Christmas Eve (12 day), Memorial Day, Thanksgiving Day, Christmas Day, Independence Day, Day after Thanksgiving, New Years Eve (12 day).'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bot.generate(\"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKXYPltxdx5s"
      },
      "source": [
        "# Implementing Paper Recommendations\n",
        "\n",
        "Now to implement the cohere's algorithm as well as other suggestions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b8CwVWz4dtV0"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 0.8, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "\n",
        "        self.Cohere_client = cohere.Client(api_key=os.environ.get(\"COHERE_API_KEY\"))\n",
        "\n",
        "        #Case 4: (chain of thought with few shot examples)\n",
        "        self.Employee_Template = \"\"\"\n",
        "            You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "            Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "            Follow these steps to construct your response:\n",
        "            1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "            2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "            3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "            4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "            5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "            Examples:\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "            Question:\n",
        "            \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "            2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "            3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "            4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "            5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "            Question:\n",
        "            \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "            2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "            3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "            4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "            5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "            ---\n",
        "            {question}\n",
        "            Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        search_query = query + \" try to answer from \" + relevant_docs\n",
        "\n",
        "        retrieved_docs = self.format_docs_rerank(self.vector_store.similarity_search(search_query))\n",
        "        # print(\"retrieved docs are: \", retrieved_docs)\n",
        "        reranked_docs = self.rerank(query, retrieved_docs)\n",
        "        # print(\"reranked docs are: \", reranked_docs)\n",
        "\n",
        "        context = self.reformat_docs(reranked_docs)\n",
        "\n",
        "        print(\"\\n\\nAnd now the re-ranked final context is: \", context)\n",
        "\n",
        "        contextualised_query = \"Context: \\n\" + context + \"\\n Question: \\n\" + query\n",
        "\n",
        "        query_response = self.Employee_chain.invoke({\"question\": contextualised_query}) #figure out a way to invoke using the retrieved documents.... we dont actually need to have the route functionality, as i will add a final guardrail call at the end.\n",
        "\n",
        "        match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "        if self.verbose:\n",
        "          return query_response\n",
        "        else:\n",
        "          return match.group(1) if match else \"\"\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "\n",
        "    def rerank(self, query, chunks):\n",
        "        \"\"\"\n",
        "        Reranks chunks based on relevance to the query using Cohere's re-rank endpoint.\n",
        "\n",
        "        :param query: The query string\n",
        "        :param chunks: A list of chunk strings to rerank\n",
        "        :return: A list of tuples (chunk, score) sorted by score in descending order\n",
        "        \"\"\"\n",
        "        print(\"The raw chunks received are: \")\n",
        "        for chunk in chunks:\n",
        "          print(chunk)\n",
        "        responses = self.Cohere_client.rerank(\n",
        "            query=query,\n",
        "            documents=chunks,\n",
        "            top_n=len(chunks)  # Return scores for all chunks\n",
        "        )\n",
        "\n",
        "        # print(\"[IN RERANK] responses are: \", responses)\n",
        "\n",
        "        # Sort the chunks by their relevance scores\n",
        "        # Extract the indexes based on relevance score\n",
        "        relevant_indexes = [item.index for item in responses.results]\n",
        "        # Return the chunks at the relevant indexes\n",
        "        return [chunks[i] for i in relevant_indexes][:2]\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    def format_docs_rerank(self, docs):\n",
        "      return [d.page_content for d in docs]\n",
        "\n",
        "    def reformat_docs(self, docs):\n",
        "      return \"\\n\\n\".join([d for d in docs])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Yu3lbimulmdq",
        "outputId": "7305aeef-0130-4a81-cf61-586dbea88ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The raw chunks received are: \n",
            " and will convey that to the employees prior to making the appointment.  Seasonal Employment  Seasonal employees shall be compensated at a rate established by the annual City budget process. 9  Paid Time Off  Holidays & Floating Holidays  Eligibility All full-time and part-time employees working at least 20 hours per week are eligible to receive compensation for holidays; temporary or limited-term employees are not eligible. The Holiday calendar for a given year is published in the fall of the year before with the specific holiday schedule. This is the general list of holidays.  - New Years Day - Labor Day - Christmas Eve (12 day) - Memorial Day - Thanksgiving Day - Christmas Day - Independence Day - Day after Thanksgiving - New Years Eve (12 day)  If a holiday falls on a Saturday, the preceding Friday shall be considered the observed holiday just as Monday will be considered for holidays falling on a Sunday.   Pay Rate & Working on a Holiday Holiday pay will be computed at the employees regular rate of pay and at the regular number of scheduled work hours. No employee shall be compensated more than once for any holiday. If a non-exempt employee is required to work on an actual or observed holiday, the City will pay their straight time rate for all hours\n",
            " a Friday or a Sunday, they will be converted into an additional floating holiday as well. New employees are eligible for holiday pay after 90 days of employment.  Vacation The City believes that employees need time away from work each year and provides eligible employees with paid vacation time according to the schedule below and, when it pertains, in the written Union contracts.   Eligibility Employees will generally be granted paid vacation benefits as of January 1st each year based on their length of continuous service. Along those lines, if an employee is hired between January 1st and June 30th, they will receive 1 week of vacation that they are able to use after 90 days of employment. 10   Years of Continuous Service Weeks of Vacation    Non-Exempt  Less than 8 years 2 8  14 years 3 15  19 years 4 20 years or more 5   Exempt Less than 4 years 2 4  14 years 3 15  19 years 4 20 years or more 5    Union employees should check their contracts for specific vacation information.   Vacation Carryover Not permitted: In limited instances, employees may be allowed to carryover vacation days into the next year. To qualify for the carryover provisions, a request must be submitted justifying the\n",
            ", too (e.g. customer support, shipping.) If you work in these departments, you will follow a shift schedule as needed. Paid time off (PTO) Employees receive 20 days of Paid Time Off (PTO) per year. You PTO accrual begins the day you join our company and you receive 1.7 days per month. You can take your PTO at any time after your first week with us and you can use time off you havent accrued yet. You will earn one additional day per year after your first year with our company, with a cap at 25 days overall.  If you want to use PTO, send a request through our HRIS. If your manager or HR approves, you are permitted to take your leave. You do not have to specify a reason for requesting PTO.  You cancannot transfer any remaining PTO to the next year. We encourage you to use your time off throughout the year.  If you leave our company, we may compensate accrued PTO with your final paycheck according to local law. When the law doesnt have provisions, we will compensate accrued leave to employees who were not terminated for cause. Holidays Our company observes the following holidays:   New Years Day  Martin Luther\n",
            "EMPLOYEE COMPENSATION  & BENEFITS GUIDE City of Fond du Lac   Introduction This Guide was created to provide guidelines to aid all employees of the City of Fond du Lac in understanding their compensation and benefits that relate to their employment with the City. It contains general statements of City policy and should not be read as including the fine details of each policy, nor as forming an express or implied contract or promise that the policies discussed in it will be applied in all cases. The City may add to this guide or revoke or modify it from time to time. The City will try to keep this guide current, but there may be times when a policy will change before this material can be revised, published and communicated. Notice: This Guide generally applies to all employees. However, in some instances employees who were hired before January 1, 2012 may be entitled to certain benefits that are not contained in this guide. The Human Resources Department is available to answer any questions regarding all human resource issues including benefit eligibility and questions. 2 3  Compensation Salary Administration The compensation strategy is based upon pay plans and policies that determine the classification of jobs into pay grades and pay steps. Exceptions to the pay plan may be made by the City Council.  The current salary schedule\n",
            "\n",
            "\n",
            "And now the re-ranked final context is:   and will convey that to the employees prior to making the appointment.  Seasonal Employment  Seasonal employees shall be compensated at a rate established by the annual City budget process. 9  Paid Time Off  Holidays & Floating Holidays  Eligibility All full-time and part-time employees working at least 20 hours per week are eligible to receive compensation for holidays; temporary or limited-term employees are not eligible. The Holiday calendar for a given year is published in the fall of the year before with the specific holiday schedule. This is the general list of holidays.  - New Years Day - Labor Day - Christmas Eve (12 day) - Memorial Day - Thanksgiving Day - Christmas Day - Independence Day - Day after Thanksgiving - New Years Eve (12 day)  If a holiday falls on a Saturday, the preceding Friday shall be considered the observed holiday just as Monday will be considered for holidays falling on a Sunday.   Pay Rate & Working on a Holiday Holiday pay will be computed at the employees regular rate of pay and at the regular number of scheduled work hours. No employee shall be compensated more than once for any holiday. If a non-exempt employee is required to work on an actual or observed holiday, the City will pay their straight time rate for all hours\n",
            "\n",
            "EMPLOYEE COMPENSATION  & BENEFITS GUIDE City of Fond du Lac   Introduction This Guide was created to provide guidelines to aid all employees of the City of Fond du Lac in understanding their compensation and benefits that relate to their employment with the City. It contains general statements of City policy and should not be read as including the fine details of each policy, nor as forming an express or implied contract or promise that the policies discussed in it will be applied in all cases. The City may add to this guide or revoke or modify it from time to time. The City will try to keep this guide current, but there may be times when a policy will change before this material can be revised, published and communicated. Notice: This Guide generally applies to all employees. However, in some instances employees who were hired before January 1, 2012 may be entitled to certain benefits that are not contained in this guide. The Human Resources Department is available to answer any questions regarding all human resource issues including benefit eligibility and questions. 2 3  Compensation Salary Administration The compensation strategy is based upon pay plans and policies that determine the classification of jobs into pay grades and pay steps. Exceptions to the pay plan may be made by the City Council.  The current salary schedule\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The list of holidays for which you can be compensated while working at least 20 hours per week at the City of Fond du Lac includes: New Year's Day, Labor Day, Christmas Eve (half day), Memorial Day, Thanksgiving Day, Christmas Day, Independence Day, Day after Thanksgiving, and New Year's Eve (half day).\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bot = EmployeeChatBot()\n",
        "bot.generate(\"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvTmUhfyhnLh"
      },
      "source": [
        "#Reflection:\n",
        "\n",
        "So This re-ranker works well, and honestly the only thing i wanted to try out. I will now place the guardrail and try evaluation, from the 10 questions i have gathered. and see if i need to augment prompt anymore."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
