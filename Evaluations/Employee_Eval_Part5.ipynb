{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VusnTOXAlVL"
      },
      "source": [
        "# Employee Eval Part 5\n",
        "\n",
        "#### This notebook intended to contain the final code for Employee class after all decision making and evaluations. However, i decided to do a analysis on the memory aspect of application as well, i think this simple memory implementation along with the prompt seem to work fine.\n",
        "\n",
        "I am thinking to limit the cache and memory to last 5 responses, however."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-dm99umAvGj",
        "outputId": "01d0b428-04e9-4a11-c738-0ab45aa62820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.12 (from langchain_community)\n",
            "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4.0,>=0.3.12->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.24\n",
            "    Uninstalling langchain-core-0.3.24:\n",
            "      Successfully uninstalled langchain-core-0.3.24\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.2\n",
            "    Uninstalling langchain-text-splitters-0.3.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.11\n",
            "    Uninstalling langchain-0.3.11:\n",
            "      Successfully uninstalled langchain-0.3.11\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 langchain_community-0.3.12 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.26.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.25)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.2.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.20.3)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.1.2\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting aiohttp<3.10,>=3.9.5 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.3.25)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (0.2.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (4.66.6)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (2.27.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.2.2)\n",
            "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client, aiohttp, langchain_pinecone\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.10\n",
            "    Uninstalling aiohttp-3.11.10:\n",
            "      Successfully uninstalled aiohttp-3.11.10\n",
            "Successfully installed aiohttp-3.9.5 langchain_pinecone-0.2.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, pinecone\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 1.1.0\n",
            "    Uninstalling pinecone-plugin-inference-1.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone-client 5.0.1 requires pinecone-plugin-inference<2.0.0,>=1.0.3, but you have pinecone-plugin-inference 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "Installing collected packages: pinecone-plugin-inference\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 3.1.0\n",
            "    Uninstalling pinecone-plugin-inference-3.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-plugin-inference-1.1.0\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement difflib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for difflib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting cohere\n",
            "  Downloading cohere-5.13.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, fastavro, cohere\n",
            "Successfully installed cohere-5.13.3 fastavro-1.9.7 parameterized-0.9.0 types-requests-2.32.0.20241016\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.13.3)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "#pip installing:\n",
        "%pip install langchain\n",
        "%pip install langchain_community\n",
        "%pip install langchain_huggingface\n",
        "%pip install langchain_pinecone\n",
        "%pip install pinecone\n",
        "%pip install pinecone-client\n",
        "%pip install dotenv\n",
        "%pip install streamlit\n",
        "%pip install pymupdf\n",
        "%pip install -qU langchain_community wikipedia\n",
        "%pip install --upgrade --quiet langchain-text-splitters tiktoken\n",
        "%pip install difflib\n",
        "%pip install cohere\n",
        "%pip install cohere\n",
        "\n",
        "\n",
        "import os\n",
        "import langchain #its giving module not found error\n",
        "import langchain_community\n",
        "import langchain_huggingface\n",
        "import langchain_pinecone\n",
        "import pinecone\n",
        "import dotenv\n",
        "import streamlit as st\n",
        "\n",
        "# Additional Imports (loading document):\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "#pinecone etc (storage of ducments):\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from uuid import uuid4\n",
        "\n",
        "#hugging face etc (for generation):\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "#memory imports\n",
        "#I used these documentations: https://python.langchain.com/v0.1/docs/use_cases/chatbots/memory_management/ , https://python.langchain.com/v0.1/docs/modules/memory/types/buffer/ , https://python.langchain.com/v0.1/docs/modules/memory/\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import create_history_aware_retriever #new\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#caching imports:\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "#for timing the retrivals\n",
        "import time\n",
        "\n",
        "#for parsing:\n",
        "import re\n",
        "\n",
        "#for cohere:\n",
        "import cohere\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTsCC8TAAvQ5",
        "outputId": "a23f9f5a-a445-4d5a-a937-3e2ff45be4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables are saved to .env file.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace with the API keys you need\n",
        "HUGGINGFACE_API_KEY = \"\"\n",
        "PINECONE_API_KEY = \"\"\n",
        "COHERE_API_KEY = \"\"\n",
        "\n",
        "env_content = f\"\"\"\n",
        "HUGGINGFACE_API_KEY={HUGGINGFACE_API_KEY}\n",
        "PINECONE_API_KEY={PINECONE_API_KEY}\n",
        "COHERE_API_KEY={COHERE_API_KEY}\n",
        "\"\"\"\n",
        "\n",
        "with open(\".env\", \"w\") as file:\n",
        "    file.write(env_content)\n",
        "\n",
        "print(\"Environment variables are saved to .env file.\")\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8nG1qGb8R9-"
      },
      "source": [
        "# Standard (w/o memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "g3HwKsOaAvZh"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 1, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "        #cache variables\n",
        "        self.cache = []\n",
        "        self.Cohere_client = cohere.Client(api_key=os.environ.get(\"COHERE_API_KEY\"))\n",
        "\n",
        "        self.General_template = \"\"\"\n",
        "          You are a helpful assistant tasked with responding to queries that are classified as \"Irrelevant\" to organizational matters. When given such a query:\n",
        "\n",
        "          1. Politely inform the user that their question does not pertain to organizational topics like IT, HR, Finance, or other departments.\n",
        "          2. If possible, redirect the user to appropriate resources or provide general guidance relevant to their question.\n",
        "          3. Maintain a polite, professional, and neutral tone in all responses.\n",
        "\n",
        "          Here are some examples:\n",
        "\n",
        "          Example 1:\n",
        "          User Query: \"What is the weather like today?\"\n",
        "          Response: \"This query is unrelated to organizational topics. You can check the weather using a reliable weather app or website like Weather.com.\"\n",
        "\n",
        "          Example 2:\n",
        "          User Query: \"What is the best way to cook pasta?\"\n",
        "          Response: \"This query is not related to organizational matters. However, you can explore cooking tips on platforms like AllRecipes or YouTube for detailed instructions.\"\n",
        "\n",
        "          Example 3:\n",
        "          User Query: \"How do I improve my fitness level?\"\n",
        "          Response: \"Your query is unrelated to organizational topics, but you might find helpful fitness tips on apps like MyFitnessPal or consulting a professional trainer.\"\n",
        "\n",
        "          Now respond to the following query:\n",
        "\n",
        "          User Query: {question}\n",
        "          Response:\n",
        "          \"\"\"\n",
        "\n",
        "\n",
        "        self.Classifier_template = \"\"\"\n",
        "          You are a prompt classifier designed to classify questions from employees in an organization.\n",
        "          Your task is to classify the following question into \"Relevant\" or \"Irrelevant,\" based on whether the query theme is related to an organization employee's concerns. These could include IT, HR, Finance, or any other department.\n",
        "\n",
        "          To determine the classification, follow these steps:\n",
        "          1. Analyze the question to identify its theme or context.\n",
        "          2. Determine if the question relates to organizational matters or internal operations.\n",
        "          3. Classify the question as \"Relevant\" if it pertains to IT, HR, Finance, or any other organizational department.\n",
        "          4. Classify the question as \"Irrelevant\" if it is unrelated to organizational matters or concerns.\n",
        "\n",
        "          Here are examples to guide you:\n",
        "          Example 1:\n",
        "          Question: \"How can I reset my email password?\"\n",
        "          Thought Process: The question is about IT support, which is an organizational concern.\n",
        "          Answer: Relevant\n",
        "\n",
        "          Example 2:\n",
        "          Question: \"What is the weather like today?\"\n",
        "          Thought Process: The question is unrelated to any organizational department.\n",
        "          Answer: Irrelevant\n",
        "\n",
        "          Example 3:\n",
        "          Question: \"How do I submit my expense report for reimbursement?\"\n",
        "          Thought Process: The question is about Finance, a department within the organization.\n",
        "          Answer: Relevant\n",
        "\n",
        "          Now classify the following question. Provide only one-word answers (\"Relevant\" or \"Irrelevant\").\n",
        "\n",
        "          Question: {question}\n",
        "          Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Employee_Template = \"\"\"\n",
        "            You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "            Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "            Follow these steps to construct your response:\n",
        "            1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "            2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "            3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "            4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "            5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "            Examples:\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "            Question:\n",
        "            \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "            2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "            3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "            4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "            5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "            Question:\n",
        "            \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "            2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "            3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "            4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "            5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "            ---\n",
        "            {question}\n",
        "            Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "        self.General_prompt = PromptTemplate( template=self.General_template, input_variables=[\"question\"] )\n",
        "        self.Classifier_prompt = PromptTemplate( template=self.Classifier_template, input_variables=[\"question\"] )\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.General_chain = ({\"question\": RunnablePassthrough()} | self.General_prompt | self.llm  | StrOutputParser() )\n",
        "        self.classifier_chain = ({\"question\": RunnablePassthrough()} | self.Classifier_prompt | self.llm  | StrOutputParser() )\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "      #Check Against Cache\n",
        "        for cached_query, cached_response in self.cache:\n",
        "          if self.similar(cached_query, query) > 0.6:\n",
        "              print(\"cache found, with: \", cached_query, \" score: \", self.similar(cached_query, query))\n",
        "              query_response = cached_response\n",
        "              if self.verbose:\n",
        "                return query_response\n",
        "              else:\n",
        "                match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "                return match.group(1) if match else query_response\n",
        "\n",
        "      #Add memory step here, implement by self, give all prev asked questions.\n",
        "\n",
        "      #Classiify whether General question or relevant to Organization.\n",
        "        classifier_response = self.classifier_chain.invoke({\"question\": query})\n",
        "        match = re.search(r'\\b(Relevant|Irrelevant)\\b', classifier_response)\n",
        "        query_class = match.group(0) if match else None\n",
        "\n",
        "      #Run the General Response\n",
        "        if query_class == \"Irrelevant\":\n",
        "          general_response = self.General_chain.invoke({\"question\": query})\n",
        "          self.cache.append([query, general_response])\n",
        "          return general_response.strip('\"').strip()\n",
        "\n",
        "      #Run the Employee Docs RAG Steps\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        search_query = query + \" try to answer from \" + relevant_docs\n",
        "        retrieved_docs = self.format_docs_rerank(self.vector_store.similarity_search(search_query))\n",
        "        reranked_docs = self.rerank(query, retrieved_docs)\n",
        "        context = self.reformat_docs(reranked_docs)\n",
        "        contextualised_query = \"Context: \\n\" + context + \"\\n Question: \\n\" + query\n",
        "        query_response = self.Employee_chain.invoke({\"question\": contextualised_query})\n",
        "\n",
        "      #Final GuardRailCheck if the answer actually answers the question (if needed)\n",
        "\n",
        "      #Store in Cache\n",
        "        self.cache.append([query, query_response])\n",
        "\n",
        "      #Check Against Verbose\n",
        "        if self.verbose:\n",
        "          return query_response\n",
        "        else:\n",
        "          match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "          return match.group(1) if match else query_response\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "    def similar(self, a, b):\n",
        "        return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "    def rerank(self, query, chunks):\n",
        "        responses = self.Cohere_client.rerank(\n",
        "            query=query,\n",
        "            documents=chunks,\n",
        "            top_n=len(chunks)  # Return scores for all chunks\n",
        "        )\n",
        "\n",
        "        # print(\"[IN RERANK] responses are: \", responses)\n",
        "\n",
        "        # Sort the chunks by their relevance scores\n",
        "        # Extract the indexes based on relevance score\n",
        "        relevant_indexes = [item.index for item in responses.results]\n",
        "        # Return the chunks at the relevant indexes\n",
        "        return [chunks[i] for i in relevant_indexes][:2]\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    def format_docs_rerank(self, docs):\n",
        "      return [d.page_content for d in docs]\n",
        "\n",
        "    def reformat_docs(self, docs):\n",
        "      return \"\\n\\n\".join([d for d in docs])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THccjF_AxIrT",
        "outputId": "01371566-9919-41dd-d07f-bd233727d7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\n",
            "\n",
            "Answer is: \n",
            "No, you should not accept the tickets without first consulting the Senior Deputy General Counsel or the Chief Legal Officer to determine whether an exception applies.\n",
            "Question is: \n",
            "At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\n",
            "\n",
            "Answer is: \n",
            "The list of holidays that full-time and part-time employees can be compensated for working at least 20 hours per week are: New Year's Day, Labor Day, Christmas Eve (12 day), Memorial Day, Thanksgiving Day, Christmas Day, Independence Day, Day after Thanksgiving, and New Year's Eve (12 day).\n",
            "Question is: \n",
            "What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\n",
            "\n",
            "Answer is: \n",
            "In the Employee Information section of the form, you should fill out your last name, first name, employee ID, position title, and department. As for the rating key, it seems to be different for the University of Texas, so I suggest you contact the appropriate department at the University of Texas to obtain the correct rating key.\n",
            "Question is: \n",
            "As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\n",
            "\n",
            "Answer is: \n",
            "If a referred candidate is hired in a hard-to-fill role, the employee may receive up to 6000 as a reward.\n",
            "Question is: \n",
            "What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\n",
            "\n",
            "Answer is: \n",
            "Your duties as a supervisor before the start date include confirming the start date, assuring background checks and paperwork have been completed, setting up the workspace, and communicating with the employee regarding their start details, such as reporting location and what to bring.\n"
          ]
        }
      ],
      "source": [
        "# All eval questions:\n",
        "\n",
        "#Init\n",
        "bot = EmployeeChatBot()\n",
        "\n",
        "#Question1\n",
        "question = \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question2\n",
        "question = \"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question3\n",
        "question = \"What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question4\n",
        "question = \"As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question5\n",
        "question = \"What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoBys9pg7YgA",
        "outputId": "ec3f5d53-800b-4c47-af7b-a1920ddd9d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\n",
            "\n",
            "Answer is: \n",
            "When working remotely, you should adhere to the weekly Project Report requirement, submit your reports to your supervisor prior to your weekly meeting, and attend meetings, such as VP Meetings or other meetings where attendance has been pre-approved, if needed.\n",
            "Question is: \n",
            "While on the topic of cyber security, in what ways can i be exploited via Emails?\n",
            "\n",
            "Answer is: \n",
            "An employee can be exploited via emails by receiving phishing attempts, malware, and spam emails. Emails with attachments, links, or suspicious content should be handled with caution and verified before opening or clicking.\n",
            "Question is: \n",
            "what are the user access control guidelines for system access control policy of the company?\n",
            "\n",
            "Answer is: \n",
            "The guidelines include pre-approval for access requests, limiting access to the appropriate level, regular reviews, adherence to the \"Least Privilege\" principle, Segregation of Duties, logging all actions, using authorized equipment, and restricting access from external sources in accordance with the Company's policies.\n",
            "Question is: \n",
            "What are the Unacceptable use scenarios of technology devices at workforce central?\n",
            "\n",
            "Answer is: \n",
            "The unacceptable use scenarios of technology devices at WorkForce Central include violating rights protected by copyright, soliciting emails, creating chain letters, spam, posting to large numbers of newsgroups, using personal social media accounts, and accessing or using WorkForce Central's intellectual property without authorization.\n",
            "Question is: \n",
            "how can i create expense report procurement card for Concur Travel and Expense System?\n",
            "\n",
            "Answer is: \n",
            "To create a Procurement Card expense report on the Concur Travel & Expense System, follow these steps:\n"
          ]
        }
      ],
      "source": [
        "#Question6\n",
        "question = \"What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question7\n",
        "question = \"While on the topic of cyber security, in what ways can i be exploited via Emails?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question8\n",
        "question = \"what are the user access control guidelines for system access control policy of the company?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question9\n",
        "question = \"What are the Unacceptable use scenarios of technology devices at workforce central?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question10\n",
        "question = \"how can i create expense report procurement card for Concur Travel and Expense System?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzcKyTMozfyu"
      },
      "source": [
        "# Integrating with memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YyT3GT06zlFY"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 1, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "        #cache variables\n",
        "        self.cache = []\n",
        "        self.Cohere_client = cohere.Client(api_key=os.environ.get(\"COHERE_API_KEY\"))\n",
        "\n",
        "        self.memory_template = \"\"\"\n",
        "          You are an intelligent assistant designed to enhance the clarity of questions by analyzing their context and comparing them to previously asked questions. Your task is to:\n",
        "\n",
        "          1. Review the list of previously asked questions to understand recurring themes, topics, or context.\n",
        "          2. Compare the new question to the previous ones and determine if it is related to any of them.\n",
        "          3. If the new question is related, rewrite the question so that it is complete and unambiguous, using the relevant context from the previous questions.\n",
        "          4. If the new question is unrelated, return it as is.\n",
        "\n",
        "          Here are some examples:\n",
        "\n",
        "          ### Example 1:\n",
        "          Previously Asked Questions:\n",
        "          1. How do I reset my email password?\n",
        "          2. Where can I find the IT support portal?\n",
        "\n",
        "          New Question: What is the process?\n",
        "          Clarified Question: What is the process for resetting my email password?\n",
        "\n",
        "          ### Example 2:\n",
        "          Previously Asked Questions:\n",
        "          1. How do I submit my expense report?\n",
        "          2. What is the approval process for reimbursements?\n",
        "\n",
        "          New Question: How long does it take?\n",
        "          Clarified Question: How long does it take to approve an expense report?\n",
        "\n",
        "          ### Example 3:\n",
        "          Previously Asked Questions:\n",
        "          1. What is the weather like today?\n",
        "          2. Is it raining outside?\n",
        "\n",
        "          New Question: What should I wear?\n",
        "          Clarified Question: What should I wear based on the weather today?\n",
        "\n",
        "          ### Example 4:\n",
        "          Previously Asked Questions:\n",
        "          1. How do I change my direct deposit details?\n",
        "\n",
        "          New Question: How do I reset my password?\n",
        "          Clarified Question: How do I reset my password?\n",
        "\n",
        "          Instructions:\n",
        "          - If related, provide the clarified question in a complete form.\n",
        "          - If unrelated, provide the question as is.\n",
        "\n",
        "          Now process the following input:\n",
        "\n",
        "          {question}\n",
        "\n",
        "          Clarified Question:\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        self.General_template = \"\"\"\n",
        "          You are a helpful assistant tasked with responding to queries that are classified as \"Irrelevant\" to organizational matters. When given such a query:\n",
        "\n",
        "          1. Politely inform the user that their question does not pertain to organizational topics like IT, HR, Finance, or other departments.\n",
        "          2. If possible, redirect the user to appropriate resources or provide general guidance relevant to their question.\n",
        "          3. Maintain a polite, professional, and neutral tone in all responses.\n",
        "\n",
        "          Here are some examples:\n",
        "\n",
        "          Example 1:\n",
        "          User Query: \"What is the weather like today?\"\n",
        "          Response: \"This query is unrelated to organizational topics. You can check the weather using a reliable weather app or website like Weather.com.\"\n",
        "\n",
        "          Example 2:\n",
        "          User Query: \"What is the best way to cook pasta?\"\n",
        "          Response: \"This query is not related to organizational matters. However, you can explore cooking tips on platforms like AllRecipes or YouTube for detailed instructions.\"\n",
        "\n",
        "          Example 3:\n",
        "          User Query: \"How do I improve my fitness level?\"\n",
        "          Response: \"Your query is unrelated to organizational topics, but you might find helpful fitness tips on apps like MyFitnessPal or consulting a professional trainer.\"\n",
        "\n",
        "          Now respond to the following query:\n",
        "\n",
        "          User Query: {question}\n",
        "          Response:\n",
        "          \"\"\"\n",
        "\n",
        "\n",
        "        self.Classifier_template = \"\"\"\n",
        "          You are a prompt classifier designed to classify questions from employees in an organization.\n",
        "          Your task is to classify the following question into \"Relevant\" or \"Irrelevant,\" based on whether the query theme is related to an organization employee's concerns. These could include IT, HR, Finance, or any other department.\n",
        "\n",
        "          To determine the classification, follow these steps:\n",
        "          1. Analyze the question to identify its theme or context.\n",
        "          2. Determine if the question relates to organizational matters or internal operations.\n",
        "          3. Classify the question as \"Relevant\" if it pertains to IT, HR, Finance, or any other organizational department.\n",
        "          4. Classify the question as \"Irrelevant\" if it is unrelated to organizational matters or concerns.\n",
        "\n",
        "          Here are examples to guide you:\n",
        "          Example 1:\n",
        "          Question: \"How can I reset my email password?\"\n",
        "          Thought Process: The question is about IT support, which is an organizational concern.\n",
        "          Answer: Relevant\n",
        "\n",
        "          Example 2:\n",
        "          Question: \"What is the weather like today?\"\n",
        "          Thought Process: The question is unrelated to any organizational department.\n",
        "          Answer: Irrelevant\n",
        "\n",
        "          Example 3:\n",
        "          Question: \"How do I submit my expense report for reimbursement?\"\n",
        "          Thought Process: The question is about Finance, a department within the organization.\n",
        "          Answer: Relevant\n",
        "\n",
        "          Now classify the following question. Provide only one-word answers (\"Relevant\" or \"Irrelevant\").\n",
        "\n",
        "          Question: {question}\n",
        "          Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Employee_Template = \"\"\"\n",
        "            You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "            Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "            Follow these steps to construct your response:\n",
        "            1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "            2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "            3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "            4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "            5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "            Examples:\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "            Question:\n",
        "            \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "            2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "            3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "            4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "            5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "            ---\n",
        "            Context:\n",
        "            \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "            Question:\n",
        "            \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "            Answer:\n",
        "            1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "            2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "            3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "            4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "            5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "            ---\n",
        "            {question}\n",
        "            Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "        self.Memory_prompt = PromptTemplate(template=self.memory_template, input_variables=[\"question\"])\n",
        "        self.General_prompt = PromptTemplate( template=self.General_template, input_variables=[\"question\"] )\n",
        "        self.Classifier_prompt = PromptTemplate( template=self.Classifier_template, input_variables=[\"question\"] )\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.memory_chain = ({\"question\": RunnablePassthrough()} | self.Memory_prompt | self.llm  | StrOutputParser() )\n",
        "        self.General_chain = ({\"question\": RunnablePassthrough()} | self.General_prompt | self.llm  | StrOutputParser() )\n",
        "        self.classifier_chain = ({\"question\": RunnablePassthrough()} | self.Classifier_prompt | self.llm  | StrOutputParser() )\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "      #Check Against Cache\n",
        "        for cached_query, cached_response in self.cache:\n",
        "          if self.similar(cached_query, query) > 0.6:\n",
        "              print(\"cache found, with: \", cached_query, \" score: \", self.similar(cached_query, query))\n",
        "              query_response = cached_response\n",
        "              if self.verbose:\n",
        "                return query_response\n",
        "              else:\n",
        "                match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "                return match.group(1) if match else query_response\n",
        "\n",
        "      #Add memory step here, implement by self, give all prev asked questions.\n",
        "        if self.cache:\n",
        "          previous_questions = \"\\n\".join([entry[0] for entry in self.cache])\n",
        "        else:\n",
        "          previous_questions = \"\"\n",
        "        memory_query = \"Previous_questions: \\n\" + previous_questions + \"\\nNew Question: \\n\" + query\n",
        "        memory_response = self.memory_chain.invoke({\"question\": memory_query})\n",
        "        print(f\"Original query: {query} Memory query: {memory_response}\")\n",
        "        query = memory_response\n",
        "\n",
        "      #Classiify whether General question or relevant to Organization.\n",
        "        classifier_response = self.classifier_chain.invoke({\"question\": query})\n",
        "        match = re.search(r'\\b(Relevant|Irrelevant)\\b', classifier_response)\n",
        "        query_class = match.group(0) if match else None\n",
        "\n",
        "      #Run the General Response\n",
        "        if query_class == \"Irrelevant\":\n",
        "          general_response = self.General_chain.invoke({\"question\": query})\n",
        "          self.cache.append([query, general_response])\n",
        "          return general_response.strip('\"').strip()\n",
        "\n",
        "      #Run the Employee Docs RAG Steps\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        search_query = query + \" try to answer from \" + relevant_docs\n",
        "        retrieved_docs = self.format_docs_rerank(self.vector_store.similarity_search(search_query))\n",
        "        reranked_docs = self.rerank(query, retrieved_docs)\n",
        "        context = self.reformat_docs(reranked_docs)\n",
        "        contextualised_query = \"Context: \\n\" + context + \"\\n Question: \\n\" + query\n",
        "        query_response = self.Employee_chain.invoke({\"question\": contextualised_query})\n",
        "\n",
        "      #Final GuardRailCheck if the answer actually answers the question (if needed)\n",
        "\n",
        "      #Store in Cache\n",
        "        self.cache.append([query, query_response])\n",
        "\n",
        "      #Check Against Verbose\n",
        "        if self.verbose:\n",
        "          return query_response\n",
        "        else:\n",
        "          match = re.search(r\"\\*\\*Provide the answer\\*\\*: (.*?)(?:\\n|$)\", query_response)\n",
        "          return match.group(1) if match else query_response\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "    def similar(self, a, b):\n",
        "        return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "    def rerank(self, query, chunks):\n",
        "        responses = self.Cohere_client.rerank(\n",
        "            query=query,\n",
        "            documents=chunks,\n",
        "            top_n=len(chunks)  # Return scores for all chunks\n",
        "        )\n",
        "\n",
        "        # print(\"[IN RERANK] responses are: \", responses)\n",
        "\n",
        "        # Sort the chunks by their relevance scores\n",
        "        # Extract the indexes based on relevance score\n",
        "        relevant_indexes = [item.index for item in responses.results]\n",
        "        # Return the chunks at the relevant indexes\n",
        "        return [chunks[i] for i in relevant_indexes][:2]\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    def format_docs_rerank(self, docs):\n",
        "      return [d.page_content for d in docs]\n",
        "\n",
        "    def reformat_docs(self, docs):\n",
        "      return \"\\n\\n\".join([d for d in docs])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO2MlUse4e5h",
        "outputId": "784395af-5c61-46c7-9e77-db34a40fb2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\n",
            "Original query: One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets? Memory query:  If I win the raffle at Comerica's client's open house, can I accept the free airline tickets?\n",
            "\n",
            "Answer is: \n",
            "\"This query pertains to Comerica's client's open house raffle and the potential winnings. However, it does not relate directly to organizational matters such as IT, HR, Finance, or other departments within our company. I would recommend reaching out to the contact provided at the event or inquiring with the client for clarification on the raffle rules and any associated prizes.\n",
            "Question is: \n",
            "At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\n",
            "Original query: At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week? Memory query:  At City of Fond du Lac, what is the list of holidays that I can be compensated for working at least 20 hours per week? (The question is unrelated to Comerica's client's open house, so it is provided as is.)\n",
            "\n",
            "Answer is: \n",
            "The list of holidays includes: New Years Day, Labor Day, Christmas Eve (12 day), Memorial Day, Thanksgiving Day, Christmas Day, Independence Day, Day after Thanksgiving, and New Years Eve (12 day).\n",
            "Question is: \n",
            "What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\n",
            "Original query: What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided? Memory query:  What are the details I have to add in the \"Employee Information\" section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\n",
            "\n",
            "Answer is: \n",
            "To fill out the \"Employee Information\" section for the Employee Appraisal Form at the University of Texas, you will need the following information: name, ID, position title, department, and an answer to the question about whether they are a supervisor. I have not been provided the rating key for the University of Texas, so you should contact the relevant personnel or HR department for that information.\n",
            "Question is: \n",
            "As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\n",
            "Original query: As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role? Memory query:  As per the Recruitment section of the employee handbook, what is my reward if someone is recruited from my referral in a hard-to-fill role?\n",
            "\n",
            "Answer is: \n",
            "If you refer a candidate who is hired for a hard-to-fill role, such as Data Scientist, you may receive a reward of 6000.\n",
            "Question is: \n",
            "What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\n",
            "Original query: What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston? Memory query:  What are my duties as a supervisor, before the start date, when onboarding new employees at the University of Houston?\n",
            "\n",
            "Answer is: \n",
            "As a supervisor, your duties before the new employee's start date include confirming the start date, sending a welcome email with relevant information, ensuring the workspace is move-in ready, contacting IT for computer and phone setup, ordering any required uniforms, equipment, or supplies, and setting up a first-week schedule. You may also need to arrange for keys, fingerprint scanning (if applicable), and new hire online training.\n"
          ]
        }
      ],
      "source": [
        "# All eval questions:\n",
        "\n",
        "#Init\n",
        "bot = EmployeeChatBot()\n",
        "\n",
        "#Question1\n",
        "question = \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question2\n",
        "question = \"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question3\n",
        "question = \"What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question4\n",
        "question = \"As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question5\n",
        "question = \"What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFjd6M1n4f4l",
        "outputId": "081594bd-1137-4251-90fd-2d3c3578656d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\n",
            "Original query: What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely? Memory query:  What are the productivity measures if I want to work remotely, and are there any meetings I have to attend if I am working remotely, considering the context of my work duties and the employee handbooks from Comerica's client, City of Fond du Lac, the University of Texas, and the University of Houston.\n",
            "\n",
            "Answer is: \n",
            "When working remotely at Comerica, you are required to submit a Project Report outlining your work, updates, and any approvals needed from your supervisor. You should also ensure that you have a fast and secure internet connection, work in a quiet place, and check in with your team frequently. It is unclear from the context whether there are specific meetings that you are required to attend, as policies for other organizations were not provided.\n",
            "Question is: \n",
            "While on the topic of cyber security, in what ways can i be exploited via Emails?\n",
            "Original query: While on the topic of cyber security, in what ways can i be exploited via Emails? Memory query:  While on the topic of cyber security, in what ways can I be exploited via emails at Comerica's client, City of Fond du Lac, the University of Texas, and the University of Houston?\n",
            "\n",
            "Answer is: \n",
            "You could be exploited via emails by phishing attacks, malware, or unintentional data disclosures. To minimize risk, be cautious when opening attachments, clicking links, and providing personal or confidential information via email. Report any suspicious emails to your IT department.\n",
            "Question is: \n",
            "what are the user access control guidelines for system access control policy of the company?\n",
            "Original query: what are the user access control guidelines for system access control policy of the company? Memory query:  What are the user access control guidelines for the system access control policy of Comerica's client, City of Fond du Lac, the University of Texas, and the University of Houston?\n",
            "\n",
            "Answer is: \n",
            "The guidelines for user access control in the system access control policies of City of Fond du Lac, the University of Texas, and the University of Houston are likely to involve limiting access to necessary users, controlling data access rights, and implementing risk management strategies, although the specifics may differ between organizations. To obtain accurate and detailed information, you should review each organization's system access control policy.\n",
            "Question is: \n",
            "What are the Unacceptable use scenarios of technology devices at workforce central?\n",
            "Original query: What are the Unacceptable use scenarios of technology devices at workforce central? Memory query:  What are the unacceptable use scenarios of technology devices at work, considering the context of Comerica's client, City of Fond du Lac, the University of Texas, and the University of Houston?\n",
            "\n",
            "Answer is: \n",
            "Unacceptable use scenarios for technology devices at work, according to the policy, may include (but are not limited to):\n",
            "Question is: \n",
            "how can i create expense report procurement card for Concur Travel and Expense System?\n",
            "Original query: how can i create expense report procurement card for Concur Travel and Expense System? Memory query:  How can I create an expense report procurement card for the Concur Travel and Expense System, considering the context of the questions related to expense reports?\n",
            "\n",
            "Answer is: \n",
            "To create a Procurement Card expense report on the Concur Travel & Expense System, follow these steps:\n"
          ]
        }
      ],
      "source": [
        "#Question6\n",
        "question = \"What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question7\n",
        "question = \"While on the topic of cyber security, in what ways can i be exploited via Emails?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question8\n",
        "question = \"what are the user access control guidelines for system access control policy of the company?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question9\n",
        "question = \"What are the Unacceptable use scenarios of technology devices at workforce central?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question10\n",
        "question = \"how can i create expense report procurement card for Concur Travel and Expense System?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
