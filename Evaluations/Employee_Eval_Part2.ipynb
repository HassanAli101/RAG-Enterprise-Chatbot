{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PeaIqjx7YVO"
      },
      "source": [
        "# Employee Eval Part 2:\n",
        "\n",
        "This includes testing out different LLMs from hugging face with different params to pick the optimal one, both size and performance wise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "draFtwys7tNa",
        "outputId": "8b5598b7-fb38-449a-a02c-0bba028d9831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.12 (from langchain_community)\n",
            "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4.0,>=0.3.12->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.24\n",
            "    Uninstalling langchain-core-0.3.24:\n",
            "      Successfully uninstalled langchain-core-0.3.24\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.2\n",
            "    Uninstalling langchain-text-splitters-0.3.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.11\n",
            "    Uninstalling langchain-0.3.11:\n",
            "      Successfully uninstalled langchain-0.3.11\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 langchain_community-0.3.12 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.26.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.25)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.2.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.20.3)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.1.2\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting aiohttp<3.10,>=3.9.5 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.3.25)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (0.2.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (4.66.6)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (2.27.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.2.2)\n",
            "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client, aiohttp, langchain_pinecone\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.10\n",
            "    Uninstalling aiohttp-3.11.10:\n",
            "      Successfully uninstalled aiohttp-3.11.10\n",
            "Successfully installed aiohttp-3.9.5 langchain_pinecone-0.2.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, pinecone\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 1.1.0\n",
            "    Uninstalling pinecone-plugin-inference-1.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone-client 5.0.1 requires pinecone-plugin-inference<2.0.0,>=1.0.3, but you have pinecone-plugin-inference 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "Installing collected packages: pinecone-plugin-inference\n",
            "  Attempting uninstall: pinecone-plugin-inference\n",
            "    Found existing installation: pinecone-plugin-inference 3.1.0\n",
            "    Uninstalling pinecone-plugin-inference-3.1.0:\n",
            "      Successfully uninstalled pinecone-plugin-inference-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-plugin-inference-1.1.0\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement difflib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for difflib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting cohere\n",
            "  Downloading cohere-5.13.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, fastavro, cohere\n",
            "Successfully installed cohere-5.13.3 fastavro-1.9.7 parameterized-0.9.0 types-requests-2.32.0.20241016\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.13.3)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "#pip installing:\n",
        "%pip install langchain\n",
        "%pip install langchain_community\n",
        "%pip install langchain_huggingface\n",
        "%pip install langchain_pinecone\n",
        "%pip install pinecone\n",
        "%pip install pinecone-client\n",
        "%pip install dotenv\n",
        "%pip install streamlit\n",
        "%pip install pymupdf\n",
        "%pip install -qU langchain_community wikipedia\n",
        "%pip install --upgrade --quiet langchain-text-splitters tiktoken\n",
        "%pip install difflib\n",
        "%pip install cohere\n",
        "%pip install cohere\n",
        "\n",
        "\n",
        "import os\n",
        "import langchain #its giving module not found error\n",
        "import langchain_community\n",
        "import langchain_huggingface\n",
        "import langchain_pinecone\n",
        "import pinecone\n",
        "import dotenv\n",
        "import streamlit as st\n",
        "\n",
        "# Additional Imports (loading document):\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "#pinecone etc (storage of ducments):\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from uuid import uuid4\n",
        "\n",
        "#hugging face etc (for generation):\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "#memory imports\n",
        "#I used these documentations: https://python.langchain.com/v0.1/docs/use_cases/chatbots/memory_management/ , https://python.langchain.com/v0.1/docs/modules/memory/types/buffer/ , https://python.langchain.com/v0.1/docs/modules/memory/\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import create_history_aware_retriever #new\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#caching imports:\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "#for timing the retrivals\n",
        "import time\n",
        "\n",
        "#for parsing:\n",
        "import re\n",
        "\n",
        "#for cohere:\n",
        "import cohere\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGGJQOip7w_p",
        "outputId": "ea1485f7-e237-4461-cb29-26d503efb954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables are saved to .env file.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace with the API keys you need\n",
        "HUGGINGFACE_API_KEY = \"\"\n",
        "PINECONE_API_KEY = \"\"\n",
        "COHERE_API_KEY = \"\"\n",
        "\n",
        "env_content = f\"\"\"\n",
        "HUGGINGFACE_API_KEY={HUGGINGFACE_API_KEY}\n",
        "PINECONE_API_KEY={PINECONE_API_KEY}\n",
        "COHERE_API_KEY={COHERE_API_KEY}\n",
        "\"\"\"\n",
        "\n",
        "with open(\".env\", \"w\") as file:\n",
        "    file.write(env_content)\n",
        "\n",
        "print(\"Environment variables are saved to .env file.\")\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyOgE5FsEn81"
      },
      "source": [
        "# Original: mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "\n",
        "This has 46.7B params and is a pretrained generative Sparse Mixture of Experts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPuZNH1DED-F"
      },
      "source": [
        "# New LLM 1: mistralai/Mistral-Nemo-Instruct-2407\n",
        "\n",
        "this has 12.2B params and is fine tuned version of Mistral-Nemo-Base-2407. Trained jointly by Mistral AI and NVIDIA, it significantly outperforms existing models smaller or similar in size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "38kJtE5S7zQj"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.retriever = self.vector_store.as_retriever( search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.5},) #tunable\n",
        "        self.repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 0.8, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "\n",
        "        #memory variables:\n",
        "        self.memory_template = \"\"\"You are a ambiguity clearer, your task is to examine the human question and check for any \"he/she/it/they/them\" ambiguities.\n",
        "        return an updated human question fixing those ambiguities using the previous conversation context only.\n",
        "        if there is not enought relevant context, RETURN HUMAN QUESTION AS IT IS\n",
        "        YOUR ANSWER SHOULD BE A QUESTION WHICH ONLY CLARIFIES ANY AMBIGUITY IN human question by replacing it with their name\n",
        "        RETURN IN FORMAT: New human question: (updated question)\n",
        "        Previous conversation:\n",
        "        {chat_history}\n",
        "\n",
        "        human question: {question}\n",
        "        New human question:\n",
        "        \"\"\"\n",
        "        self.memory_prompt = PromptTemplate.from_template(self.memory_template)\n",
        "\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "        self.conversation = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.memory_prompt,\n",
        "            verbose=False,\n",
        "            memory=self.memory\n",
        "        )\n",
        "        #prompt variables\n",
        "        self.Classifier_template = \"\"\"\n",
        "        You are a prompt classifier designed to classify questions from employees in an organization.\n",
        "        classify the following question into \"Relevant\" or \"Irrelevant\", based on whether the query theme is of a question from an organization employee, the question could be about IT, HR, Finance or any other department\n",
        "        Only answer from the specified classes and one word answers.\n",
        "\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #Case 1:\n",
        "        self.Employee_Template = \"\"\"\n",
        "          You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "          Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "          Follow these steps to construct your response:\n",
        "          1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "          2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "          3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "          4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "          5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "          Examples:\n",
        "          ---\n",
        "          Context:\n",
        "          \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "          Question:\n",
        "          \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "          Answer:\n",
        "          1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "          2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "          3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "          4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "          5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "          ---\n",
        "          Context:\n",
        "          \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "          Question:\n",
        "          \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "          Answer:\n",
        "          1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "          2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "          3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "          4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "          5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "          ---\n",
        "          Context: {context}\n",
        "          Question: {question}\n",
        "          Answer:\n",
        "      \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        self.Classifier_prompt = PromptTemplate( template=self.Classifier_template, input_variables=[\"question\"] )\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.classifier_chain = ({\"question\": RunnablePassthrough()} | self.Classifier_prompt | self.llm  | StrOutputParser() )\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"context\": self.retriever | self.format_docs,  \"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "        self.full_chain = {\"Relevancy\": self.classifier_chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(self.route)\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "        # print(f\"Generating with system prompt: {self.Employee_Template}\")\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        query = query + \" try to answer from \" + relevant_docs\n",
        "        print(f\"Augmented Query is: {query}\")\n",
        "        query_response = self.full_chain.invoke({\"question\": query})\n",
        "        return query_response\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "    def route(self, info):\n",
        "        if \"relevant\" in info[\"Relevancy\"].lower():\n",
        "          # print(\"Question was relevant\")\n",
        "          return self.Employee_chain.invoke(info[\"question\"])\n",
        "        else:\n",
        "          return \"Your question was not relevant to our organization\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovhsNbfU723P",
        "outputId": "e3d87eaf-4670-4f15-fcb0-f360e08723cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\n",
            "Augmented Query is: One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets? try to answer from Code-of-conduct, Compensation-Benefits-Guide\n",
            "\n",
            "Answer is: \n",
            " ```\n",
            "Question is: \n",
            "At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\n",
            "Augmented Query is: At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week? try to answer from Health-and-Safety-Guidelines\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What are the holidays for which an employee working at least 20 hours per week at the City of Fond du Lac can be compensated?\n",
            "       2. **Analyze the context**: The provided context lists general holidays and rules for observed holidays, as well as eligibility criteria for holiday pay.\n",
            "       3. **Evaluate implications**: The employee is eligible for holiday pay as they work at least 20 hours per week. The listed holidays are applicable.\n",
            "       4. **Provide the answer**: The list of holidays for which you can be compensated, if working at least 20 hours per week, are:\n",
            "          - New Years Day\n",
            "          - Memorial Day\n",
            "          - Independence Day\n",
            "          - Labor Day\n",
            "          - Thanksgiving Day\n",
            "          - Christmas Eve (observed on the preceding Friday if it falls on a Saturday)\n",
            "          - Christmas Day (observed on the following Monday if it falls on a Sunday)\n",
            "          - New Years Eve (observed on the following Monday if it falls on a Sunday)\n",
            "          Additionally, if a holiday falls on a Saturday, the preceding Friday is considered the observed holiday, and if it falls on a Sunday, the following Monday is observed.\n",
            "       5. **Reflection**: I have provided the list of holidays based on the given context and the employee's eligibility for holiday pay.\n",
            "Question is: \n",
            "What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\n",
            "Augmented Query is: What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided? try to answer from \n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What are the specific details to be filled in the \"Employee Information\" section of the University of Texas's Employee Appraisal Form, and what are the ratings defined in the provided Rating Key?\n",
            "       2. **Analyze the context**: The provided context includes an example of an Employee Appraisal Form with sections for \"Employee Information\" and a \"Rating Key\" outlining performance levels.\n",
            "       3. **Evaluate implications**: The information is self-explanatory, and there's no need for further interpretation or application of policies.\n",
            "       4. **Provide the answer**: **Employee Information** section details to be filled:\n",
            "            - Last Name\n",
            "            - First Name\n",
            "            - Employee ID\n",
            "            - Position Title\n",
            "            - Department\n",
            "            - \"Is this person a supervisor?\" (Yes/No)\n",
            "            - Evaluation Type (e.g., Probation, Ending Probation, Annual Review)\n",
            "            - Appraisal Period Start Date\n",
            "            - Appraisal Period End Date\n",
            "\n",
            "            **Rating Key**:\n",
            "            - EP - 5: Exceptional Performance\n",
            "            - PE - 4: Periodic Exceptional Performance\n",
            "            - SP - 3: Satisfactory Performance\n",
            "            - IP - 2: Inconsistent Performance\n",
            "       5. **Reflection**: The context provided directly answers the question, so my response simply summarizes the relevant details from the given form.\n",
            "Question is: \n",
            "As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\n",
            "Augmented Query is: As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role? try to answer from \n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What reward does the employee receive for referring a candidate for a hard-to-fill role?\n",
            "       2. **Analyze the context**: The policy states that rewards may be higher for hard-to-fill roles. If the referred candidate is hired as a Data Scientist, the employee referral reward is $6,000.\n",
            "       3. **Evaluate implications**: Since the question does not specify a role, we'll assume the employee is asking about the maximum reward for a hard-to-fill role.\n",
            "       4. **Provide the answer**: If the referred candidate is hired for a hard-to-fill role like Data Scientist, you are eligible for a $6,000 referral bonus.\n",
            "       5. **Reflection**: I based my answer on the specific example provided in the context, assuming it represents the highest reward for a hard-to-fill role.\n",
            "Question is: \n",
            "What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\n",
            "Augmented Query is: What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston? try to answer from Employee-Handbook\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What tasks must I, as a supervisor, complete before a new employee's start date at the University of Houston?\n",
            "       2. **Analyze the context**: The provided context is an excerpt from an onboarding checklist for the University of Houston. It outlines both employee and supervisor duties before the start date.\n",
            "       3. **Evaluate implications**: Ensuring all these tasks are completed helps create a smooth onboarding process, setting the new employee up for success.\n",
            "       4. **Provide the answer**: As a supervisor, your duties before the start date include:\n",
            "       - Assuring that the background check and other paperwork has been completed.\n",
            "       - Confirming the start date.\n",
            "       - Sending a welcome email with relevant information (template provided).\n",
            "       - Setting up the workspace as move-in ready by coordinating with IT, Access Control, and ordering any necessary uniforms, equipment, or supplies.\n",
            "       - Providing the new employee with an introduction packet, if applicable.\n",
            "       - Regularly communicating with the new employee leading up to their start date.\n",
            "       - Creating a first week schedule and printing off the New Hire Online Training list.\n",
            "       - Selecting a buddy for the new employee and ensuring the buddy is comfortable with their role in supporting the new hire.\n",
            "       5. **Reflection**: I've based my answer on the clear instructions provided in the onboarding checklist, ensuring you have a comprehensive understanding of your responsibilities as a supervisor.\n"
          ]
        }
      ],
      "source": [
        "# All eval questions:\n",
        "\n",
        "#Init\n",
        "bot = EmployeeChatBot()\n",
        "\n",
        "#Question1\n",
        "question = \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question2\n",
        "question = \"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question3\n",
        "question = \"What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question4\n",
        "question = \"As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question5\n",
        "question = \"What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b83Gl0Qf75Si",
        "outputId": "9a326761-06fb-4341-ab36-f0b20fbb0a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\n",
            "Augmented Query is: What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely? try to answer from Onboarding-Manual, Remote-Work-Policy\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: The employee wants to know the productivity measures and mandatory meetings for remote work, as outlined in the provided policies.\n",
            "       2. **Analyze the context**: The \"Onboarding-Manual\" and \"Remote-Work-Policy\" documents describe productivity expectations, meetings, and other aspects of remote work.\n",
            "       3. **Evaluate implications**: Remote work requires adherence to specific guidelines to maintain productivity and collaboration.\n",
            "       4. **Provide the answer**:\n",
            "            - **Productivity Measures**:\n",
            "              - Remote employees must submit a weekly Project Report to their supervisor outlining their tasks, updates, questions, and approvals needed.\n",
            "              - They should use a fast and secure internet connection, suitable devices, and a quiet workspace.\n",
            "              - Regular check-ins with the team are encouraged to facilitate collaboration.\n",
            "            - **Mandatory Meetings**:\n",
            "              - Remote employees are required to attend the weekly All Staff Meeting, as well as any other meetings relevant to their projects or teams.\n",
            "              - Vice Presidents (VPs) are permitted to attend all meetings in person or virtually but are exempt from attending meetings when on approved PTO.\n",
            "              - Comp Time may not be taken during the weekly scheduled CEO meeting or the weekly All Staff meeting.\n",
            "       5. **Reflection**: I've summarized the key points from the provided policies regarding productivity measures and mandatory meetings for remote work, ensuring that the employee is well-informed about their responsibilities and expectations.\n",
            "Question is: \n",
            "While on the topic of cyber security, in what ways can i be exploited via Emails?\n",
            "Augmented Query is: While on the topic of cyber security, in what ways can i be exploited via Emails? try to answer from \n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What are the main methods by which an employee can be exploited via emails for cyber attacks?\n",
            "       2. **Analyze the context**: The context discusses four common phishing techniques that target employees through emails.\n",
            "       3. **Evaluate implications**: Understanding these techniques helps employees recognize and avoid potential email-based cyber attacks.\n",
            "       4. **Provide the answer**: Here are the four primary ways an employee can be exploited via emails:\n",
            "          - **Phishing Links**: Emails may contain links that redirect users to unsecured websites where sensitive information is requested.\n",
            "          - **Malicious Attachments**: Emails might include attachments that install Trojans or other malware, allowing intruders to exploit system vulnerabilities and steal sensitive information.\n",
            "          - **Spoofed Emails**: Phishers may spoof the sender address to appear as a reputable source, tricking employees into revealing sensitive information or performing actions that benefit the attacker.\n",
            "          - **Phishing Calls**: Attackers may impersonate known company vendors or IT departments over the phone, attempting to obtain company information or trick employees into performing actions that compromise security.\n",
            "       5. **Reflection**: By being aware of these techniques, employees can better protect themselves and the company from email-based cyber attacks.\n",
            "Question is: \n",
            "what are the user access control guidelines for system access control policy of the company?\n",
            "Augmented Query is: what are the user access control guidelines for system access control policy of the company? try to answer from Code-of-conduct, Compensation-Benefits-Guide\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: What are the user access control guidelines for the company's system access control policy, focusing on Code-of-conduct and Compensation-Benefits-Guide?\n",
            "       2. **Analyze the context**: The provided context discusses user access control in detail, outlining procedures, principles, and review processes. However, it does not mention Code-of-conduct or Compensation-Benefits-Guide.\n",
            "       3. **Evaluate implications**: Since the asked guides are not mentioned in the provided context, they might not be relevant to the user access control guidelines.\n",
            "       4. **Provide the answer**: Based on the given context, the user access control guidelines for the company's system access control policy include:\n",
            "          - Following the \"Least Privilege\" principle, granting access only as necessary.\n",
            "          - Enforcing Segregation of Duties among employees.\n",
            "          - Regularly reviewing and revoking access rights, with special attention to privileged and remote access accounts.\n",
            "          - Ensuring that all access-related actions are logged.\n",
            "          - Requiring external service providers or partners to comply with the company's IT security policies and Third-Party Code of Conduct.\n",
            "       5. **Reflection**: While the asked guides were not mentioned, the answer is based on the explicit information provided in the context about user access control guidelines.\n",
            "Question is: \n",
            "What are the Unacceptable use scenarios of technology devices at workforce central?\n",
            "Augmented Query is: What are the Unacceptable use scenarios of technology devices at workforce central? try to answer from Code-of-conduct, Compensation-Benefits-Guide\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: The employee wants to know the unacceptable use scenarios of technology devices at WorkForce Central.\n",
            "       2. **Analyze the context**: The provided context outlines the Technology Devices Acceptable Use & Security Policy, which includes guidelines on appropriate and inappropriate use of devices.\n",
            "       3. **Evaluate implications**: The policy aims to protect the organization from risks and legal issues, and employees should adhere to these guidelines to maintain a secure and productive work environment.\n",
            "       4. **Provide the answer**: Based on the policy, the following are unacceptable use scenarios:\n",
            "          - Violating local, state, federal, or international laws while using WorkForce Central-owned resources.\n",
            "          - Engaging in activities that infringe on the rights of others, such as copyright, trade secret, patent, or trademark violations.\n",
            "          - Transmitting or distributing malicious software, such as viruses, worms, Trojan horses, or spyware.\n",
            "          - Attempting to access, alter, or damage data or systems without authorization.\n",
            "          - Sharing personal information about other employees, clients, or partners without explicit consent.\n",
            "          - Using WorkForce Central resources for personal gain or unauthorized commercial activities.\n",
            "          - Engaging in activities that disrupt or interfere with the normal operation of WorkForce Central's network or systems.\n",
            "          - Attempting to bypass or circumvent security measures or access controls.\n",
            "          - Refusing to comply with requests from the IT team or management regarding device security and maintenance.\n",
            "       5. **Reflection**: I have summarized the unacceptable use scenarios from the provided policy, ensuring that the employee is aware of the prohibited activities to maintain a secure and ethical work environment.\n",
            "Question is: \n",
            "how can i create expense report procurement card for Concur Travel and Expense System?\n",
            "Augmented Query is: how can i create expense report procurement card for Concur Travel and Expense System? try to answer from Code-of-conduct, Compensation-Benefits-Guide\n",
            "\n",
            "Answer is: \n",
            " 1. **Understand the question**: The employee wants to create an expense report for a procurement card in Concur Travel & Expense System.\n",
            "       2. **Analyze the context**: The provided context is a step-by-step guide for creating a procurement card expense report in Concur. It covers accessing the system, naming the report, and adding expenses.\n",
            "       3. **Evaluate implications**: There are no apparent rules, policies, or ethical considerations mentioned in the context that would affect the process of creating an expense report.\n",
            "       4. **Provide the answer**: To create a procurement card expense report in Concur Travel & Expense System, follow these steps:\n",
            "          - Access Concur via your campus portal, locate CU Resources, and select the Concur Travel & Expense System link.\n",
            "          - Click 'New Expense Report' and select 'Procurement Card' from the Policy dropdown on the Report Header page.\n",
            "          - Name your expense report, enter comments (optional), and click 'Next'.\n",
            "          - You will then proceed to Step 2, where you can add expenses to your report.\n",
            "       5. **Reflection**: I based my answer on the explicit steps outlined in the provided context, which is a guide specifically designed for creating procurement card expense reports in Concur.\n"
          ]
        }
      ],
      "source": [
        "#Question6\n",
        "question = \"What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question7\n",
        "question = \"While on the topic of cyber security, in what ways can i be exploited via Emails?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question8\n",
        "question = \"what are the user access control guidelines for system access control policy of the company?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question9\n",
        "question = \"What are the Unacceptable use scenarios of technology devices at workforce central?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question10\n",
        "question = \"how can i create expense report procurement card for Concur Travel and Expense System?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpnHdHpLEbcU"
      },
      "source": [
        "# New LLM 2: mistralai/Mistral-7B-Instruct-v0.3\n",
        "\n",
        "This has 7.25B params, is an instruct fine-tuned version of the Mistral-7B-v0.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "joMqBhvfBuOy"
      },
      "outputs": [],
      "source": [
        "class EmployeeChatBot:\n",
        "    # TODO: To be implemented\n",
        "    def __init__(self):\n",
        "        #loading variables:\n",
        "        self.combined_text = \"\"\n",
        "        self.CHUNK_SIZE = 256\n",
        "        self.CHUNK_OVERLAP = 0.50\n",
        "        #storing variables:\n",
        "        self.pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "        self.index_name = \"employee-queries-db\" #keep the name small\n",
        "        self.embeddings = HuggingFaceEmbeddings()\n",
        "        self.index = self.pc.Index(self.index_name) #Remember, i can do this because i have already once created this index, else create index first\n",
        "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embeddings)\n",
        "        # generating variables\n",
        "        self.retriever = self.vector_store.as_retriever( search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.5},) #tunable\n",
        "        self.repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #tunable\n",
        "        self.llm = HuggingFaceEndpoint( repo_id=self.repo_id, temperature= 0.8, top_k= 50, huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY') ) #tunable\n",
        "\n",
        "        self.verbose = False #change this to see the explanations of how the LLM reached its conclusion\n",
        "\n",
        "        #memory variables:\n",
        "        self.memory_template = \"\"\"You are a ambiguity clearer, your task is to examine the human question and check for any \"he/she/it/they/them\" ambiguities.\n",
        "        return an updated human question fixing those ambiguities using the previous conversation context only.\n",
        "        if there is not enought relevant context, RETURN HUMAN QUESTION AS IT IS\n",
        "        YOUR ANSWER SHOULD BE A QUESTION WHICH ONLY CLARIFIES ANY AMBIGUITY IN human question by replacing it with their name\n",
        "        RETURN IN FORMAT: New human question: (updated question)\n",
        "        Previous conversation:\n",
        "        {chat_history}\n",
        "\n",
        "        human question: {question}\n",
        "        New human question:\n",
        "        \"\"\"\n",
        "        self.memory_prompt = PromptTemplate.from_template(self.memory_template)\n",
        "\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "        self.conversation = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.memory_prompt,\n",
        "            verbose=False,\n",
        "            memory=self.memory\n",
        "        )\n",
        "        #prompt variables\n",
        "        self.Classifier_template = \"\"\"\n",
        "        You are a prompt classifier designed to classify questions from employees in an organization.\n",
        "        classify the following question into \"Relevant\" or \"Irrelevant\", based on whether the query theme is of a question from an organization employee, the question could be about IT, HR, Finance or any other department\n",
        "        Only answer from the specified classes and one word answers.\n",
        "\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #Case 1:\n",
        "        self.Employee_Template = \"\"\"\n",
        "          You are a highly knowledgeable and reflective chatbot designed to assist employees of an organization by answering their questions accurately and thoughtfully.\n",
        "          Your goal is to provide well-reasoned and clear answers based on the provided context.\n",
        "\n",
        "          Follow these steps to construct your response:\n",
        "          1. **Understand the question**: Restate the question in simpler terms if necessary, ensuring you grasp the key aspects of what is being asked.\n",
        "          2. **Analyze the context**: Examine the provided context and identify relevant information that applies to the question.\n",
        "          3. **Evaluate implications**: Consider any potential rules, policies, or ethical considerations that could affect the answer.\n",
        "          4. **Provide the answer**: Deliver a clear, concise, and actionable response based on your analysis.\n",
        "          5. **Reflection**: Briefly explain your reasoning process to ensure transparency and to help the employee understand your conclusion.\n",
        "\n",
        "          Examples:\n",
        "          ---\n",
        "          Context:\n",
        "          \"Employees are prohibited from accepting gifts valued over $50 from clients. If a gift exceeds this amount, it must be declined or reported to the ethics committee.\"\n",
        "\n",
        "          Question:\n",
        "          \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "\n",
        "          Answer:\n",
        "          1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event?\n",
        "          2. **Analyze the context**: The policy prohibits accepting gifts over $50. Airline tickets are likely valued well over this limit and would need to be reported or declined.\n",
        "          3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
        "          4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies.\n",
        "          5. **Reflection**: I based my answer on the explicit policy regarding gift value limits and the need to maintain ethical boundaries with clients.\n",
        "          ---\n",
        "          Context:\n",
        "          \"Employees are allowed to attend client-sponsored events, such as dinners or conferences, provided the primary purpose is business-related and attendance has been pre-approved by their manager.\"\n",
        "\n",
        "          Question:\n",
        "          \"A client has invited me to a dinner event to discuss our ongoing project. Do I need approval to attend?\"\n",
        "\n",
        "          Answer:\n",
        "          1. **Understand the question**: Does the employee need prior approval to attend a client dinner for business purposes?\n",
        "          2. **Analyze the context**: The policy states that attendance at client events requires pre-approval from the employee’s manager.\n",
        "          3. **Evaluate implications**: While the event seems business-related, attending without prior approval could breach company protocol.\n",
        "          4. **Provide the answer**: Yes, you need to get approval from your manager before attending the dinner.\n",
        "          5. **Reflection**: My answer aligns with the policy, ensuring adherence to company guidelines while allowing participation in legitimate business activities.\n",
        "          ---\n",
        "          Context: {context}\n",
        "          Question: {question}\n",
        "          Answer:\n",
        "      \"\"\"\n",
        "\n",
        "        self.Augment_Prompt_Template = \"\"\"\n",
        "            The following are the file names available in our database:\n",
        "            HR:\n",
        "            - Code-of-conduct\n",
        "            - Compensation-Benefits-Guide\n",
        "            - Employee-appraisal-form\n",
        "            - Employee-Handbook\n",
        "            - Employee-Termination-Policy\n",
        "            - Health-and-Safety-Guidelines\n",
        "            - Onboarding-Manual\n",
        "            - Remote-Work-Policy\n",
        "\n",
        "            IT:\n",
        "            - Cybersecurity-for-Employees\n",
        "            - System-Access-Control-Policy\n",
        "            - Technology-Devices-Policy\n",
        "\n",
        "            Finance:\n",
        "            - Expense-Report\n",
        "\n",
        "            Given the following query:\n",
        "            {question}\n",
        "\n",
        "            You are tasked with identifying and returning the names of the **two most relevant files**, separated by \"and,\" that are most helpful for addressing the query.\n",
        "            do NOT provide reasoning or add any other text, just the names of files\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        self.Classifier_prompt = PromptTemplate( template=self.Classifier_template, input_variables=[\"question\"] )\n",
        "        self.Employee_prompt = PromptTemplate(template=self.Employee_Template, input_variables=[\"context\", \"question\"] )\n",
        "        self.get_relevant_docs_prompt = PromptTemplate( template=self.Augment_Prompt_Template, input_variables=[\"question\"] )\n",
        "\n",
        "        #chain variables\n",
        "        self.classifier_chain = ({\"question\": RunnablePassthrough()} | self.Classifier_prompt | self.llm  | StrOutputParser() )\n",
        "        self.get_relevant_docs_chain = ({\"question\": RunnablePassthrough()} | self.get_relevant_docs_prompt | self.llm  | StrOutputParser() )\n",
        "        self.Employee_chain = ({\"context\": self.retriever | self.format_docs,  \"question\": RunnablePassthrough()} | self.Employee_prompt | self.llm | StrOutputParser() )\n",
        "        self.full_chain = {\"Relevancy\": self.classifier_chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(self.route)\n",
        "\n",
        "\n",
        "    #this function will add the given filepath (as a string) to the pinecone vector db after parsing it\n",
        "    def AddFileToDB(self, docs_to_load):\n",
        "      # [ADD LOADING AND PARSING AND CHUNKING PART HERE]\n",
        "      combined_text = \"\"\n",
        "      for doc in docs_to_load:\n",
        "        loader = PyMuPDFLoader(doc)\n",
        "        documents = loader.load()\n",
        "        # print(documents)\n",
        "        for page in documents:\n",
        "          text = page.page_content\n",
        "          if \"contents\" in text.lower():\n",
        "            continue\n",
        "          text = re.sub(r'\\bPage\\s+\\d+\\b', '', text, flags=re.IGNORECASE)\n",
        "          text = re.sub(r'\\n', '', text).strip() #removing all newlines\n",
        "          # print(text)\n",
        "          text = re.sub(r'[^\\w\\s.,?!:;\\'\\\"()&-]', '', text)\n",
        "          combined_text += text + \" \"\n",
        "      combined_text = combined_text.strip()\n",
        "      # print(combined_text)\n",
        "      text_splitter = TokenTextSplitter(chunk_size=self.CHUNK_SIZE, chunk_overlap=int(self.CHUNK_SIZE*self.CHUNK_OVERLAP))\n",
        "      texts = text_splitter.split_text(combined_text)\n",
        "      docs = text_splitter.create_documents(texts)\n",
        "      print(docs)\n",
        "      if self.index_name not in self.pc.list_indexes().names():\n",
        "        self.pc.create_index(  #tunable\n",
        "          name=self.index_name,\n",
        "          dimension=768,\n",
        "          metric=\"cosine\",\n",
        "          spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "      embeddings = HuggingFaceEmbeddings()\n",
        "      index = self.pc.Index(self.index_name)\n",
        "      vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "      uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "      vector_store.add_documents(documents=docs, ids=uuids)\n",
        "\n",
        "\n",
        "    # TODO: To be implemented\n",
        "    def generate(self, query):\n",
        "        # print(f\"Generating with system prompt: {self.Employee_Template}\")\n",
        "        relevant_docs = self.get_relevant_docs(query)\n",
        "        query = query + \" try to answer from \" + relevant_docs\n",
        "        print(f\"Augmented Query is: {query}\")\n",
        "        query_response = self.full_chain.invoke({\"question\": query})\n",
        "        return query_response\n",
        "\n",
        "    #Implement as per paper 1 with self generated text and break down of question into subsequent parts\n",
        "    def Augment_prompt(self, query):\n",
        "      pass\n",
        "\n",
        "\n",
        "    # So this is what i had a theory about\n",
        "    def get_relevant_docs(self,query):\n",
        "        augmented_prompt = self.get_relevant_docs_chain.invoke({\"question\": query})\n",
        "        documents = [\n",
        "            \"Code-of-conduct\", \"Compensation-Benefits-Guide\", \"Employee-appraisal-form\",\n",
        "            \"Employee-Handbook\", \"Employee-Termination-Policy\", \"Health-and-Safety-Guidelines\",\n",
        "            \"Onboarding-Manual\", \"Remote-Work-Policy\", \"Cybersecurity-for-Employees\",\n",
        "            \"System-Access-Control-Policy\", \"Technology-Devices-Policy\", \"Expense-Report\"\n",
        "        ]\n",
        "        words = augmented_prompt.split()\n",
        "        matches = [doc for doc in documents if doc in words]\n",
        "        return \", \".join(matches[:2])\n",
        "\n",
        "\n",
        "    #Helper functions:\n",
        "    def format_docs(self, docs):\n",
        "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "    def route(self, info):\n",
        "        if \"relevant\" in info[\"Relevancy\"].lower():\n",
        "          # print(\"Question was relevant\")\n",
        "          return self.Employee_chain.invoke(info[\"question\"])\n",
        "        else:\n",
        "          return \"Your question was not relevant to our organization\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etjOXlRzB9lZ",
        "outputId": "bbc878c4-7201-47ef-aecf-7734436b3e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\n",
            "Augmented Query is: One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets? try to answer from Remote-Work-Policy\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: Can the employee accept free airline tickets won in a raffle at a client's event under the remote work policy?\n",
            "      2. **Analyze the context**: The policy doesn't directly address this situation, but it pertains to the gift policy.\n",
            "      3. **Evaluate implications**: Accepting the tickets could violate the company's ethics policy, even if won in a raffle, as they are provided by a client.\n",
            "      4. **Provide the answer**: No, you should not accept the tickets without first consulting the ethics committee to determine whether an exception applies, as it is not addressed in the remote work policy.\n",
            "      5. **Reflection**: I based my answer on the explicit gift policy, as the remote work policy does not address this situation. It is important to maintain ethical boundaries with clients to prevent any potential conflicts of interest.\n",
            "Question is: \n",
            "At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\n",
            "Augmented Query is: At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week? try to answer from Employee-Termination-Policy\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: The employee wants to know which holidays they can receive compensation for if they work at least 20 hours per week.\n",
            "      2. **Analyze the context**: The provided context does not include the list of holidays for which employees can be compensated. However, it does state that employees working at least 20 hours per week are eligible for holiday compensation.\n",
            "      3. **Evaluate implications**: To answer the question, I need to look for the list of holidays for which employees can be compensated.\n",
            "      4. **Provide the answer**: The City of Fond du Lac offers the following holidays for compensation: New Years Day, Martin Luther King Day, Presidents Day, Good Friday, Easter Monday, Memorial Day, Independence Day, Labor Day, Columbus Day, Veterans Day, Thanksgiving Day, Christmas Day. If a holiday falls on a day when the company doesn't operate (e.g., Sunday), it will be observed on the closest business day. Employees can also take a floating day as a holiday of their choice.\n",
            "      5. **Reflection**: I based my answer on the general list of holidays provided in the context and the information about holiday compensation eligibility for employees working at least 20 hours per week. I did not use the Employee-Termination-Policy context as it does not contain the required information to answer the question.\n",
            "Question is: \n",
            "What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\n",
            "Augmented Query is: What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided? try to answer from Employee-Handbook\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: The question asks for the details to fill in the \"Employee Information\" section of the University of Texas' Employee Appraisal Form and the provided Rating Key.\n",
            "      2. **Analyze the context**: The context is an appraisal form that requires information such as employee name, employee ID, position title, and department. The Rating Key provided consists of four performance levels: Exceptional Performance (EP), Periodic Exceptional Performance (PE), Satisfactory Performance (SP), and Inconsistent Performance (IP).\n",
            "      3. **Evaluate implications**: The employee should provide accurate and complete information in the \"Employee Information\" section to ensure proper identification and evaluation. The Rating Key provides a standard for assessing job performance.\n",
            "      4. **Provide the answer**: In the \"Employee Information\" section, you should include the employee's last name, first name, employee ID, position title, and department. The Rating Key for the appraisal is as follows: EP - 5 Exceptional Performance, PE - 4 Periodic Exceptional Performance, SP - 3 Satisfactory Performance, and IP - 2 Inconsistent Performance.\n",
            "      5. **Reflection**: My answer is based on the provided appraisal form and the Rating Key, ensuring accurate completion of the form and clear communication of the performance evaluation criteria.\n",
            "Question is: \n",
            "As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\n",
            "Augmented Query is: As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role? try to answer from Onboarding-Manual\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: What is the reward for referring a candidate who gets hired in a hard-to-fill role?\n",
            "      2. **Analyze the context**: The policy states that rewards for successful referrals may be increased for hard-to-fill roles, such as Data Scientist.\n",
            "      3. **Evaluate implications**: The specific amount for a hard-to-fill role, like Data Scientist, is provided in the provided context (6000). Other hard-to-fill roles may have different reward amounts.\n",
            "      4. **Provide the answer**: If you refer a candidate who gets hired for a hard-to-fill role like Data Scientist, you may receive a 6000 referral bonus or an Amazon coupon.\n",
            "      5. **Reflection**: I based my answer on the specific example of a hard-to-fill role (Data Scientist) and the associated reward amount provided in the context. Other hard-to-fill roles may have different reward amounts.\n",
            "Question is: \n",
            "What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\n",
            "Augmented Query is: What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston? try to answer from Employee-Handbook\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: As a supervisor, what are my duties before the start date when onboarding new employees at the University of Houston?\n",
            "      2. **Analyze the context**: The provided context outlines various onboarding tasks for both employees and supervisors.\n",
            "      3. **Evaluate implications**: The supervisor's role is crucial in ensuring a smooth onboarding process, setting expectations, and providing necessary resources for the new employee.\n",
            "      4. **Provide the answer**: As a supervisor, your duties include confirming the start date, sending a welcome email with necessary information, preparing the workspace, and arranging for any equipment or uniforms. You should also arrange for introductions to co-workers, provide a tour of the department, and discuss expectations and job responsibilities.\n",
            "      5. **Reflection**: My answer is based on the provided onboarding checklist and the emphasis on the supervisor's role in the onboarding process, as outlined in the University of Houston employee handbook.\n"
          ]
        }
      ],
      "source": [
        "# All eval questions:\n",
        "\n",
        "#Init\n",
        "bot = EmployeeChatBot()\n",
        "\n",
        "#Question1\n",
        "question = \"One of Comerica's clients is hosting an open house that includes a raffle for some free airline tickets. If I win, can I accept the tickets?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question2\n",
        "question = \"At City of Fond du Lac, what is the list of holidays that i can be compensated as working atleast 20 hours per week?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question3\n",
        "question = \"What are the details i have to add in \\“Employee Information\\” section of the Employee Appraisal Form for the University of Texas, and what is the Rating Key they have provided?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question4\n",
        "question = \"As per the Recruitment section of the employee handbook, what is my reward if i someone is recruited from my referral in a hard-to-fill role?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question5\n",
        "question = \"What are my duties as a supervisor, before the start date, when onboarding new employees at the university of houston?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t40fGxtLCEAQ",
        "outputId": "0112f98d-afdc-40a3-a9ae-54b546f7087a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question is: \n",
            "What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\n",
            "Augmented Query is: What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely? try to answer from Onboarding-Manual\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: What are the productivity requirements and meetings for employees working remotely?\n",
            "      2. **Analyze the context**: The context mentions that remote employees must submit a weekly Project Report, attend the Friday All Staff meeting virtually, and have similar software as the office computers.\n",
            "      3. **Evaluate implications**: Productivity expectations are outlined in the Project Report, and virtual attendance at the Friday All Staff meeting is mandatory.\n",
            "      4. **Provide the answer**: To work remotely, you are expected to submit a weekly Project Report and attend the Friday All Staff meeting virtually. Additionally, you must have similar software to office computers.\n",
            "      5. **Reflection**: My response aligns with the provided context, ensuring that the employee understands the expectations for productivity and attendance while working remotely.\n",
            "Question is: \n",
            "While on the topic of cyber security, in what ways can i be exploited via Emails?\n",
            "Augmented Query is: While on the topic of cyber security, in what ways can i be exploited via Emails? try to answer from Cybersecurity-for-Employees, System-Access-Control-Policy\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: The question asks for ways an individual can be exploited via emails in the context of Cybersecurity for Employees and System Access Control Policy.\n",
            "      2. **Analyze the context**: The context includes a system access control policy and a focus on cybersecurity for employees. This suggests potential email-related threats related to system access and cybersecurity.\n",
            "      3. **Evaluate implications**: Email-related cybersecurity threats may include phishing, malware, and unauthorized access. These threats can lead to data breaches, identity theft, and system compromise.\n",
            "      4. **Provide the answer**: Emails can be exploited via phishing, where cybercriminals attempt to acquire sensitive information such as usernames, passwords, and credit card data by masquerading as a trustworthy entity. They may also install malware via malicious email attachments or links to unsecured websites. Furthermore, spoofing the sender address in an email can make it appear as if the email comes from a trusted source.\n",
            "      5. **Reflection**: My answer is based on the provided context, the focus on email-related threats, and the importance of cybersecurity for employees. It is crucial to be aware of these threats to avoid falling victim to them and maintain the security of both personal and company information.\n",
            "Question is: \n",
            "what are the user access control guidelines for system access control policy of the company?\n",
            "Augmented Query is: what are the user access control guidelines for system access control policy of the company? try to answer from System-Access-Control-Policy\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: What are the guidelines for user access control in the System Access Control Policy of the company?\n",
            "      2. **Analyze the context**: The policy outlines controls for user access to the company's information systems, including the review and approval process, restrictions based on work responsibilities, segregation of duties, and periodic reviews of user access rights.\n",
            "      3. **Evaluate implications**: Proper user access control ensures the accuracy and integrity of data, segregates user responsibilities, and minimizes security risks.\n",
            "      4. **Provide the answer**: The guidelines for user access control in the System Access Control Policy include:\n",
            "          - User access requests are reviewed and approved according to the ISMS-PC-01 User Access Request Procedure.\n",
            "          - Authorized users have access to the appropriate level according to work responsibilities following the \"Least Privilege\" principle.\n",
            "          - Appropriate Segregation of Duties is implemented among employees to prevent unauthorized access.\n",
            "          - User access rights are reviewed at least once a year, with more frequent reviews for users with special privileges or remote access rights.\n",
            "          - User system access rights are revoked immediately when a user no longer requires access.\n",
            "          - Each user has their own user account and must use that account throughout their tenure with the company.\n",
            "      5. **Reflection**: I based my answer on the provided context, focusing on the aspects of the policy that pertain to user access control guidelines.\n",
            "Question is: \n",
            "What are the Unacceptable use scenarios of technology devices at workforce central?\n",
            "Augmented Query is: What are the Unacceptable use scenarios of technology devices at workforce central? try to answer from Cybersecurity-for-Employees, Technology-Devices-Policy\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: List the unacceptable use scenarios of technology devices at WorkForce Central, as outlined in the Technology Devices Acceptable Use & Security Policy.\n",
            "      2. **Analyze the context**: The policy provides a list of activities that are generally prohibited, with exceptions for certain job responsibilities.\n",
            "      3. **Evaluate implications**: Engaging in any of these activities could lead to risks, including virus attacks, network compromise, compliance concerns, and potential legal issues.\n",
            "      4. **Provide the answer**: The unacceptable use scenarios include:\n",
            "          - Violating the rights of any person or company protected by copyright, trade secret, patent, or other intellectual property laws.\n",
            "          - Engaging in any activity that is illegal under local, state, federal, or international law while utilizing WorkForce Central-owned resources.\n",
            "          - Accessing, altering, copying, or destroying WorkForce Central data, programs, or other information without authorization.\n",
            "          - Sharing WorkForce Central resources, including usernames, passwords, or other authentication credentials, with unauthorized individuals.\n",
            "          - Using technology devices for personal financial gain or commercial activities unrelated to WorkForce Central business.\n",
            "          - Engaging in any activity that interferes with WorkForce Central's network services, systems, or other users.\n",
            "          - Downloading, installing, or running unauthorized software on WorkForce Central-issued technology devices.\n",
            "          - Accessing, transmitting, or storing inappropriate content, including but not limited to pornography, hate speech, or other offensive materials.\n",
            "      5. **Reflection**: My answer is based on the provided policy, outlining the specific activities that are strictly prohibited in the use of WorkForce Central's technology devices to maintain cybersecurity and adhere to legal and ethical guidelines.\n",
            "Question is: \n",
            "how can i create expense report procurement card for Concur Travel and Expense System?\n",
            "Augmented Query is: how can i create expense report procurement card for Concur Travel and Expense System? try to answer from Expense-Report\n",
            "\n",
            "Answer is: \n",
            "1. **Understand the question**: The user wants to know how to create a Procurement Card expense report in the Concur Travel & Expense System.\n",
            "      2. **Analyze the context**: The provided context outlines the steps for creating a Procurement Card expense report, starting with accessing Concur via the campus portal and selecting the New Expense Report tab.\n",
            "      3. **Evaluate implications**: The user needs to follow these steps to successfully create the expense report.\n",
            "      4. **Provide the answer**: To create a Procurement Card expense report in Concur Travel & Expense System, follow these steps:\n",
            "         a. Access Concur via your campus portal.\n",
            "         b. Locate your CU Resources section and, under the Business Applications area, select the Concur Travel & Expense System link.\n",
            "         c. From the Active Work section of your Concur home page, click the New Expense Report tab.\n",
            "         d. On the Report Header page, use the Policy dropdown and select Procurement Card.\n",
            "         e. Name your expense report for tracking and reporting purposes.\n",
            "         f. The Report Header SpeedType will default to the SpeedType assigned to your Procurement Card.\n",
            "         g. Your Approving Officials (AO) name and employee ID will populate the Report Header.\n",
            "         h. Enter comments that apply to the entire expense report in this Comment field.\n",
            "         i. The Alternate Contact Employee field identifies who should be contacted if there is a question on this expense report.\n",
            "         j. Click Next.\n",
            "      5. **Reflection**: My answer is based on the provided context, which outlines the step-by-step process for creating a Procurement Card expense report in Concur Travel & Expense System. The user can now follow these steps to complete their expense report.\n"
          ]
        }
      ],
      "source": [
        "#Question6\n",
        "question = \"What are the productivity measures if i want to work remotely and are there any meetings i have to attend if i am working remotely?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question7\n",
        "question = \"While on the topic of cyber security, in what ways can i be exploited via Emails?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question8\n",
        "question = \"what are the user access control guidelines for system access control policy of the company?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question9\n",
        "question = \"What are the Unacceptable use scenarios of technology devices at workforce central?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)\n",
        "\n",
        "#Question10\n",
        "question = \"how can i create expense report procurement card for Concur Travel and Expense System?\"\n",
        "print(\"Question is: \\n\" + question)\n",
        "answer = bot.generate(question)\n",
        "print(\"\\nAnswer is: \\n\" + answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
